{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "\n",
    "class neuralNetwork:\n",
    "    # 初始化函数\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # 输入层节点数，隐藏层节点数。输出层节点数\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        # 学习率\n",
    "        self.lr = learningrate\n",
    "        # 生成权重矩阵，这里平方0.5是为了得到0-1之间的数\n",
    "        # 输入层与隐藏层之间的权重矩阵\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        # 隐藏层与输出层之间的权重矩阵\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        # 定义匿名函数（激活函数）\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "    # 训练函数\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # 输入的节点，和目标节点\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "    # 查询函数\n",
    "    def query(self, inputs_list):\n",
    "        # 输入的节点\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        # 隐藏层乘以权重输出的节点（进行激活函数前）\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # 隐藏层输出节点（进行激活函数后）\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # 最终乘以权重输出的节点（进行激活函数前）\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # 最终层输出节点（进行激活函数后）\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs\n",
    "        \n",
    "    \n",
    "# 输入层节点，隐藏层节点。输出层节点\n",
    "inputnodes = 784\n",
    "hiddennodes = 100\n",
    "outputnodes = 10\n",
    "# 学习率\n",
    "learningrate = 0.3\n",
    "# 创建神经网络对象\n",
    "n = neuralNetwork(inputnodes, hiddennodes, outputnodes, learningrate)\n",
    "# 加载训练集\n",
    "training_data_file = open('./csv/mnist_100.csv', 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# 循环所有训练数据\n",
    "for record in training_data_list: \n",
    "    # 切割逗号为数组\n",
    "    all_values = record.split(',')\n",
    "    # 输入节点\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # 目标节点（不能使用0和1，所以使用0.01 和 0.99 表示）\n",
    "    targets = numpy.zeros(outputnodes) + 0.01\n",
    "    targets[int(all_values[0])] = 0.99   # 这是目标值\n",
    "    n.train(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 correct label\n",
      "7 network's answer\n",
      "2 correct label\n",
      "0 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "9 correct label\n",
      "4 network's answer\n",
      "5 correct label\n",
      "4 network's answer\n",
      "9 correct label\n",
      "7 network's answer\n",
      "[1, 0, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "正确率为 = 60%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# 加载测试集\n",
    "test_data_file = open('./csv/mnist_10.csv', 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "# 积分卡\n",
    "scorecard = []\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(',')\n",
    "    correct_label = int(all_values[0])\n",
    "    print(correct_label, \"correct label\")\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # 得出结果\n",
    "    outputs = n.query(inputs)\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(label, \"network's answer\")\n",
    "    if (label == correct_label):    # 正确\n",
    "        scorecard\n",
    "        scorecard.append(1)\n",
    "    else:                           # 错误\n",
    "        scorecard\n",
    "        scorecard.append(0)\n",
    "print(scorecard)\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "# 正确率\n",
    "rate = scorecard_array.sum() / scorecard_array.size * 100\n",
    "print (\"正确率为 = %.0f\" % (rate) + '%')\n",
    "\n",
    "# all_values = test_data_list[0].split(',')\n",
    "# print('实际结果为: ',all_values[0])\n",
    "# image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "# matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "# arr = n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)\n",
    "# result = numpy.argmax(arr)\n",
    "# print('预测结果为: ',result)\n",
    "# print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.27011765 0.91070588\n",
      " 0.16141176 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.25070588 0.32447059\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.47588235 0.70882353 0.16141176 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.49917647 0.64282353 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01776471\n",
      " 0.604      0.82529412 0.16529412 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.86411765 0.64282353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.11482353 0.99611765 0.63894118\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.87188235 0.64282353\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.72047059 0.99611765 0.49529412 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.18858824 0.96117647 0.64282353 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.77870588\n",
      " 0.99611765 0.22741176 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.47588235\n",
      " 0.99611765 0.64282353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.09929412 0.90682353 0.99611765 0.12258824\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.62729412 0.99611765 0.47588235\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.64282353 0.99611765 0.84858824 0.07211765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.62729412 0.99611765 0.27011765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.06435294 0.34388235 0.70105882 0.97282353 0.99611765\n",
      " 0.36329412 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.62729412\n",
      " 0.99611765 0.34       0.01       0.01       0.01       0.19247059\n",
      " 0.20023529 0.46035294 0.56905882 0.59235294 0.94564706 0.95341176\n",
      " 0.91847059 0.70494118 0.94564706 0.98835294 0.16529412 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.59235294 0.99223529 0.93011765\n",
      " 0.81364706 0.81364706 0.81364706 0.99223529 0.99611765 0.98058824\n",
      " 0.94176471 0.77870588 0.56517647 0.36329412 0.11870588 0.02941176\n",
      " 0.91458824 0.98058824 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.472      0.69717647 0.69717647 0.69717647\n",
      " 0.69717647 0.69717647 0.39047059 0.22741176 0.01       0.01\n",
      " 0.01       0.01       0.01       0.406      0.99611765 0.86411765\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 0.99611765 0.54188235 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.66611765\n",
      " 0.99611765 0.23129412 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.66611765 0.99611765 0.23129412\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 1.         0.37494118 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.66611765\n",
      " 0.99611765 0.38270588 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.66611765 0.99611765 0.604\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 1.         0.604      0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.38270588\n",
      " 0.99611765 0.604      0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "data_file = open('./csv/mnist_10.csv', 'r')\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()\n",
    "len(data_list)\n",
    "\n",
    "all_values = data_list[2].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "\n",
    "# 我们需要做的第一件事情是将输入颜色值从较大的0到255的范围，缩\n",
    "# 放至较小的0.01 到 1.0的范围。我们刻意选择0.01作为范围最低点，是为了\n",
    "# 避免先前观察到的0值输入最终会人为地造成权重更新失败。我们没有选择\n",
    "# 0.99作为输入的上限值，是因为不需要避免输入1.0会造成这个问题。我们\n",
    "# 只需要避免输出值为1.0\n",
    "# 将在0到255范围内的原始输入值除以255，就可以得到0到1范围的输入值。\n",
    "# 然后，需要将所得到的输入乘以0.99，把它们的范围变成0.0 到0.99。\n",
    "# 接下来，加上0.01，将这些值整体偏移到所需的范围0.01到1.00\n",
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "onodes = 10\n",
    "targets = numpy.zeros(onodes) + 0.01\n",
    "targets[int(all_values[0])] = 0.99\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24291681,  0.01280878, -0.96493352,  0.19718548],\n",
       "       [ 0.35465496, -0.54322577, -0.48691838,  0.19707439],\n",
       "       [-0.64714373, -0.22181575,  0.5431944 ,  0.20784809]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.normal(0.0, pow(3, -0.5), (3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13f6dc2f908>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "\n",
    "def ImageToMatrix(filename):\n",
    "    # 读取图片\n",
    "    im = PIL.Image.open(filename)\n",
    "    size = (28, 28)\n",
    "    im = im.resize(size, PIL.Image.ANTIALIAS)\n",
    "    im = numpy.array(im.convert(\"L\"))\n",
    "    imList = numpy.array([])\n",
    "    for row in im:\n",
    "        rowList = numpy.array([])\n",
    "        for i in row:\n",
    "            i = 255 - i\n",
    "            rowList = numpy.append(rowList, 0 if i < 10 else i)\n",
    "        imList = numpy.concatenate((imList, rowList))\n",
    "    return imList\n",
    "im = ImageToMatrix(\"./img/3.jpg\").reshape((28,28))\n",
    "matplotlib.pyplot.imshow(im, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
